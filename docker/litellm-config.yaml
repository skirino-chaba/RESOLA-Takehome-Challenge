model_list:
  - model_name: gpt-4
    litellm_params:
      model: openai/gpt-4
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
      temperature: 0.7
  
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
  
  - model_name: claude-3-opus
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  redis_password: os.environ/REDIS_PASSWORD
  
  # Request logging
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  
  # Langfuse config for observability
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST
  
  # Security
  block_robots: true
  enforce_user_param: true
  
router_settings:
  routing_strategy: "usage-based-routing"
  enable_pre_call_checks: true
  retry_after: 60
  num_retries: 3
  timeout: 600
  max_parallel_requests: 100
  
litellm_settings:
  drop_params: true
  enable_load_balancing: true
  set_verbose: false
  json_logs: true
  
  # Rate limiting
  max_requests_per_minute: 60
  max_tokens_per_minute: 40000
  
  # Caching
  cache: true
  cache_ttl: 3600
  
  # Cost tracking
  track_cost_callback: true